{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "captured data set will be pre-processed in three diﬀerent ways <br>\n",
    "at the end of the pre-processing, you will have three data sets: PS1, PS2, and PS3. <br>\n",
    "PS1 will contain packets, PS2 will contain ﬂows, and PS3 will only contain TCP connections. <br>\n",
    "3 datasets will be analysed separately in the data analysis phase <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import statistics\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "from distfit import distfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Wireshark->oneday.pcap\n",
    "## PS1\n",
    "oneday.pcap->Wireshark-export packet dissections as CSV->PS1.csv\n",
    "## PS2\n",
    "oneday.pcap-> crl_flow -> PS2.t2 -> t2_to_csv() -> PS2.csv\n",
    "## PS3\n",
    "oneday.pcap-> tcptrace -> oneday-tcp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for PS2 \n",
    "def t2_to_csv(input_file, output):\n",
    "    # By observing the file, we can find that blank lines and lines with \"#\" in front of them can be removed to get the clean data.\n",
    "    clean = []\n",
    "    with open(input_file , 'r') as f1:\n",
    "        for line in f1:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\") or len(line) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                x = line.split('\\t')\n",
    "                clean.append(x)\n",
    "\n",
    "    # From list to csv\n",
    "    header = ['src', 'dst', 'pro', 'ok', 'sport', 'dport', 'pkts', 'bytes',\n",
    "    'flows', 'first', 'latest']\n",
    "\n",
    "    with open(output, 'w', newline='') as f2:\n",
    "        out = csv.writer(f2)\n",
    "        out.writerow(header)\n",
    "        out.writerows(clean)\n",
    "\n",
    "t2_to_csv('./t1_data/PS2.t2','./t1_data/PS2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data analysis\n",
    "Each plot should contain a short description and also descriptive labels for the axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packet data PS1\n",
    "1.1: Visualise packet distribution by port numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist\n",
    "df_ps1 = pd.read_csv('./t1_data/PS1.csv')\n",
    "extract all port information to csv\n",
    "src_ports = []\n",
    "dst_ports = []\n",
    "for index, row in df_ps1.iterrows():\n",
    "    info = row['Info']\n",
    "    if '  >  ' in info:\n",
    "        dport = info.split('  >  ')[1].split(' ')[0]\n",
    "        dst_ports.append(int(dport))\n",
    "        sport = info.split('  >  ')[0].split(' ')[-1]\n",
    "        src_ports.append(int(sport))\n",
    "src_ports = pd.Series(src_ports)\n",
    "dst_ports = pd.Series(dst_ports)\n",
    "src_ports.to_csv(\"./t1_data/1_1_src.csv\",index=False)\n",
    "dst_ports.to_csv(\"./t1_data/1_1_dst.csv\",index=False)\n",
    "\n",
    "src_ports = pd.read_csv(\"./t1_data/1_1_src.csv\")\n",
    "dst_ports = pd.read_csv(\"./t1_data/1_1_dst.csv\")\n",
    "src_ports = src_ports.iloc[:,0]\n",
    "dst_ports = dst_ports.iloc[:,0]\n",
    "src_port_count = src_ports.unique().shape[0]\n",
    "dst_port_count = dst_ports.unique().shape[0]\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "src_ports.plot.hist(bins = src_port_count)\n",
    "plt.title(\"packet distribtion by source port\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"packets(log)\")\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "dst_ports.plot.hist(bins = dst_port_count)\n",
    "plt.title(\"packet distribtion by dst port\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"packets(log)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most common ports box plot\n",
    "src_ports = pd.read_csv(\"./t1_data/1_1_src.csv\")\n",
    "dst_ports = pd.read_csv(\"./t1_data/1_1_dst.csv\")\n",
    "src_ports = src_ports.iloc[:,0]\n",
    "dst_ports = dst_ports.iloc[:,0]\n",
    "\n",
    "# src\n",
    "ports = src_ports.value_counts().index.tolist()\n",
    "freqs = src_ports.value_counts().values.tolist()\n",
    "\n",
    "N_most_common = 10\n",
    "mc_ports = [str(x) for x in ports[0:N_most_common]]\n",
    "mc_freqs = freqs[0:N_most_common]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(mc_ports, mc_freqs)\n",
    "plt.title(str(N_most_common)+\" most common src ports\")\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"frequency\")\n",
    "\n",
    "# dst\n",
    "ports = dst_ports.value_counts().index.tolist()\n",
    "freqs = dst_ports.value_counts().values.tolist()\n",
    "\n",
    "N_most_common = 10\n",
    "mc_ports = [str(x) for x in ports[0:N_most_common]]\n",
    "mc_freqs = freqs[0:N_most_common]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(mc_ports, mc_freqs)\n",
    "plt.title(str(N_most_common)+\" most common dst ports\")\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2: Plot traﬃc volume as a function of time with at least two suﬃciently diﬀerent time scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps1 = pd.read_csv('./t1_data/PS1.csv')\n",
    "# two different time scales(in seconds)\n",
    "time_scale_1 = 60\n",
    "time_scale_2 = 300\n",
    "\n",
    "volumes_list = []\n",
    "cur_period = 0\n",
    "period_i = 0\n",
    "for index, row in df_ps1.iterrows():\n",
    "    time = float(row['Time'])\n",
    "    if time>=period_i*time_scale_1 and time<=(period_i+1)*time_scale_1:\n",
    "        cur_period += int(row['Length'])\n",
    "    else:\n",
    "        volumes_list.append(cur_period)\n",
    "        cur_period = 0\n",
    "        period_i += 1\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.array(volumes_list))\n",
    "plt.title(\"traffic volume time plot in bytes, per \"+str(time_scale_1)+\" seconds\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Traffic Volume[bytes]\")\n",
    "\n",
    "volumes_list = []\n",
    "cur_period = 0\n",
    "period_i = 0\n",
    "for index, row in df_ps1.iterrows():\n",
    "    time = float(row['Time'])\n",
    "    if time>=period_i*time_scale_2 and time<=(period_i+1)*time_scale_2:\n",
    "        cur_period += int(row['Length'])\n",
    "    else:\n",
    "        volumes_list.append(cur_period)\n",
    "        cur_period = 0\n",
    "        period_i += 1 \n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.array(volumes_list))\n",
    "plt.title(\"traffic volume time plot in bytes, per \"+str(time_scale_2)+\" seconds\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Traffic Volume[bytes]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3: Plot packet length distribution (use bins of width 1 byte), its empirical cumulative distribution function and key summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps1 = pd.read_csv('./t1_data/PS1.csv')\n",
    "lengths = df_ps1.loc[:,'Length']\n",
    "\n",
    "# histogram\n",
    "plt.figure(figsize=(16,9))\n",
    "lengths.plot.hist(bins=lengths.unique().shape[0])\n",
    "plt.title(\"Packet length distribtion histogram\")\n",
    "plt.xlabel(\"Packet length in bytes\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# key statistics\n",
    "print(\"key summary statistics\")\n",
    "print(\"Maximum: \"+str(lengths.max()))\n",
    "print(\"Minimum: \"+str(lengths.min()))\n",
    "print(\"Mean: \"+str(lengths.mean()))\n",
    "print(\"Median: \"+str(lengths.median()))\n",
    "print(\"Standard deviation: \"+str(lengths.std()))\n",
    "\n",
    "# Empirical CDF\n",
    "lengths = np.array(lengths)\n",
    "ecdf = sm.distributions.ECDF(lengths)\n",
    "x = np.linspace(0,max(lengths))\n",
    "y1 = ecdf(x)\n",
    "\n",
    "types = 'linear'\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x, y1, linewidth = '1')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('CDF')\n",
    "plt.yscale(types)\n",
    "plt.title(f'Empirical CDF of length distribution using {types} values')\n",
    "\n",
    "types = 'log'\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x, y1, linewidth = '1')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('CDF')\n",
    "plt.yscale(types)\n",
    "plt.title(f'Empirical CDF of length distribution using {types} values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow data PS2\n",
    "• 1.4: Visualise ﬂow distribution by port. <br>\n",
    "• 1.5: Plot traﬃc volume as a function of time with at least two suﬃciently diﬀerent time scales. <br>\n",
    "• 1.6: Visualise ﬂow distribution by country. Hint: use GeoIP to transform IP addresses to countries. If you have anonymised IP addresses, the results can be misleading (depending on level of anonymisation). <br>\n",
    "• 1.7: Plot origin-destination pairs both by data volume and by ﬂows (Zipf type plot). <br>\n",
    "• 1.8: Plot ﬂow length distribution, its empirical cumulative distribution function and key summary statistics. <br>\n",
    "• 1.9: Fit a distribution for the ﬂow lengths and validate the model. <br>\n",
    "• 1.10: Compare the number of ﬂows with 1, 10, 60, 120 and 1800 second timeouts. In this, you need to generate ﬂow data multiple times. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df_ps2 = pd.read_csv('./t1_data/PS2.csv')\n",
    "# sort the flow data by first time\n",
    "df_ps2 = df_ps2.sort_values('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4\n",
    "src_ports = df_ps2.loc[:,'sport']\n",
    "dst_ports = df_ps2.loc[:,'dport']\n",
    "src_port_count = src_ports.unique().shape[0]\n",
    "dst_port_count = dst_ports.unique().shape[0]\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "src_ports.plot.hist(bins = src_port_count)\n",
    "plt.title(\"packet distribtion by source port\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"packets(log)\")\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "dst_ports.plot.hist(bins = dst_port_count)\n",
    "plt.title(\"packet distribtion by dst port\")\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"packets(log)\")\n",
    "\n",
    "#src\n",
    "ports = src_ports.value_counts().index.tolist()\n",
    "freqs = src_ports.value_counts().values.tolist()\n",
    "N_most_common = 10\n",
    "mc_ports = [str(x) for x in ports[0:N_most_common]]\n",
    "mc_freqs = freqs[0:N_most_common]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(mc_ports, mc_freqs)\n",
    "plt.title(str(N_most_common)+\" most common src ports\")\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"frequency\")\n",
    "# dst\n",
    "ports = dst_ports.value_counts().index.tolist()\n",
    "freqs = dst_ports.value_counts().values.tolist()\n",
    "N_most_common = 10\n",
    "mc_ports = [str(x) for x in ports[0:N_most_common]]\n",
    "mc_freqs = freqs[0:N_most_common]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(mc_ports, mc_freqs)\n",
    "plt.title(str(N_most_common)+\" most common dst ports\")\n",
    "plt.xlabel(\"port number\")\n",
    "plt.ylabel(\"frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5\n",
    "init_time = float(df_ps2.loc[:,'first'].min())\n",
    "time_scale_1 = 60\n",
    "time_scale_2 = 300\n",
    "\n",
    "volumes_list = []\n",
    "cur_period = 0\n",
    "period_i = 0\n",
    "for index, row in df_ps2.iterrows():\n",
    "    time = float(row['first'])\n",
    "    if time-init_time >= period_i*time_scale_1 and time-init_time <= (period_i+1)*time_scale_1:\n",
    "        cur_period += int(row['bytes'])\n",
    "    else:\n",
    "        volumes_list.append(cur_period)\n",
    "        cur_period = 0\n",
    "        period_i += 1\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.array(volumes_list))\n",
    "plt.title(\"traffic volume time plot in bytes, per \"+str(time_scale_1)+\" seconds\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Traffic Volume[bytes]\")\n",
    "\n",
    "volumes_list = []\n",
    "cur_period = 0\n",
    "period_i = 0\n",
    "for index, row in df_ps2.iterrows():\n",
    "    time = float(row['first'])\n",
    "    if time-init_time >= period_i*time_scale_2 and time-init_time <= (period_i+1)*time_scale_2:\n",
    "        cur_period += int(row['bytes'])\n",
    "    else:\n",
    "        volumes_list.append(cur_period)\n",
    "        cur_period = 0\n",
    "        period_i += 1\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.array(volumes_list))\n",
    "plt.title(\"traffic volume time plot in bytes, per \"+str(time_scale_2)+\" seconds\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"Traffic Volume[bytes]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6\n",
    "src_address = df_ps2.loc[:,'src']\n",
    "dst_address = df_ps2.loc[:,'dst']\n",
    "\n",
    "from geolite2 import geolite2\n",
    "reader = geolite2.reader()\n",
    "country_count = dict()\n",
    "not_match_list = []\n",
    "\n",
    "for index, item in src_address.iteritems():\n",
    "    match = reader.get(item)\n",
    "    if match:\n",
    "        if 'country' in match:\n",
    "            country_code = match['country']['iso_code']\n",
    "        else:\n",
    "            country_code = match['continent']['code']\n",
    "        if country_code in country_count:\n",
    "            country_count[country_code] += 1\n",
    "        else:\n",
    "            country_count[country_code] = 1\n",
    "    else:\n",
    "        not_match_list.append(item)\n",
    "# country_count['OTHER'] = len(not_match_list)\n",
    "keys = country_count.keys()\n",
    "values = country_count.values()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(keys, values)\n",
    "plt.title('Flow distribution by country(source)')\n",
    "plt.xlabel('Country code')\n",
    "plt.ylabel('flow frequency')\n",
    "\n",
    "\n",
    "for index, item in dst_address.iteritems():\n",
    "    match = reader.get(item)\n",
    "    if match:\n",
    "        if 'country' in match:\n",
    "            country_code = match['country']['iso_code']\n",
    "        else:\n",
    "            country_code = match['continent']['code']\n",
    "        if country_code in country_count:\n",
    "            country_count[country_code] += 1\n",
    "        else:\n",
    "            country_count[country_code] = 1\n",
    "    else:\n",
    "        not_match_list.append(item)\n",
    "# country_count['OTHER'] = len(not_match_list)\n",
    "keys = country_count.keys()\n",
    "values = country_count.values()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(keys, values)\n",
    "plt.title('Flow distribution by country(destination)')\n",
    "plt.xlabel('Country code')\n",
    "plt.ylabel('flow frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.7\n",
    "# count pairs\n",
    "pairs = df_ps2.groupby(['src','dst'])\n",
    "t_flows = pairs['flows'].sum().reset_index().sort_values('flows',ascending=False)\n",
    "t_bytes = pairs['bytes'].sum().reset_index().sort_values('bytes',ascending=False)\n",
    "#zipf plot by bytes\n",
    "total_bytes = t_bytes.loc[:,'bytes'].sum()\n",
    "temp = t_bytes.loc[:,'bytes'].tolist()\n",
    "freqs = [item/total_bytes for item in temp]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.arange(1,len(temp)+1), freqs)\n",
    "plt.title('Zipf plot by bytes')\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('frequency')\n",
    "#zipf plot by bytes\n",
    "total_flows = t_flows.loc[:,'flows'].sum()\n",
    "temp = t_flows.loc[:,'flows'].tolist()\n",
    "freqs = [item/total_flows for item in temp]\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(np.arange(1,len(temp)+1), freqs)\n",
    "plt.title('Zipf plot by flows')\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8\n",
    "# distribution\n",
    "flow_lengths = df_ps2.loc[:,\"bytes\"]\n",
    "plt.figure(figsize=(10,8))\n",
    "flow_lengths.plot.hist(bins=100)\n",
    "plt.title(\"flow length distribtion\")\n",
    "plt.xlabel(\"length in bytes\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale('linear')\n",
    "\n",
    "# ecdf\n",
    "lengths_list = np.array(flow_lengths)\n",
    "ecdf = sm.distributions.ECDF(lengths_list)\n",
    "max1 = flow_lengths.max()\n",
    "x = np.linspace(0,max1)\n",
    "y1 = ecdf(x)\n",
    "\n",
    "types = 'linear'\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x, y1, linewidth = '1')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('CDF')\n",
    "plt.yscale(types)\n",
    "plt.title(f'Empirical CDF of length distribution using {types} values')\n",
    "\n",
    "types = 'log'\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x, y1, linewidth = '1')\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('CDF')\n",
    "plt.yscale(types)\n",
    "plt.title(f'Empirical CDF of length distribution using {types} values')\n",
    "# key statistics\n",
    "# mean, variance, max, min, median\n",
    "mean = flow_lengths.mean()\n",
    "median = flow_lengths.median()\n",
    "max = flow_lengths.max()\n",
    "min = flow_lengths.min()\n",
    "std = flow_lengths.std()\n",
    "var = flow_lengths.var()\n",
    "key_stat = {\"items\":[\"mean\",\"median\",\"max\",\"min\",\"st dev.\"],\n",
    "    \"values\":[str(x) for x in [mean,median,max,min,std]]\n",
    "}\n",
    "df = pd.DataFrame(key_stat)\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.9\n",
    "# fit and validate\n",
    "df_ps2 = pd.read_csv(\"./t1_data/PS2.csv\")\n",
    "flow_lengths = df_ps2.loc[:,\"bytes\"]\n",
    "flow_lengths = flow_lengths.values\n",
    "dist = distfit()\n",
    "dist.fit_transform(flow_lengths)\n",
    "print(dist.summary)\n",
    "dist.plot_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeout = 1 seconds\n",
      "108946\n",
      "timeout = 10 seconds\n",
      "77588\n",
      "timeout = 60 seconds\n",
      "39625\n",
      "timeout = 120 seconds\n",
      "38284\n",
      "timeout = 1800 seconds\n",
      "34748\n"
     ]
    }
   ],
   "source": [
    "# 1.10\n",
    "timeouts = [1, 10, 60, 120, 1800]\n",
    "for timeout in timeouts:\n",
    "    df = pd.read_csv(\"./t1_data/PS2-\"+str(timeout)+\".csv\")\n",
    "    print(\"timeout = \"+str(timeout)+\" seconds\")\n",
    "    print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "with open(\"./t1_data/oneday-tcp.csv\") as f:\n",
    "    for line in f:\n",
    "        if 'conn_#' in line:\n",
    "            headers = line.split(',')\n",
    "        elif '#' not in line and ',' in line:\n",
    "            data_list.append(line.split(','))\n",
    "df_ps3 = pd.DataFrame(data_list,columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrans_a2b = pd.to_numeric(df_ps3.loc[:,'max_#_retrans_a2b'])\n",
    "retrans_b2a = pd.to_numeric(df_ps3.loc[:,'max_#_retrans_b2a'])\n",
    "rtt_a2b = pd.to_numeric(df_ps3.loc[:,'RTT_samples_a2b'])\n",
    "rtt_b2a = pd.to_numeric(df_ps3.loc[:,'RTT_samples_b2a'])\n",
    "x_axis = np.arange(1,df_ps3.shape[0]+1)\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(x_axis,retrans_a2b/retrans_a2b.max(), alpha=0.5)\n",
    "plt.plot(x_axis,rtt_a2b/rtt_a2b.max(), alpha=0.5)\n",
    "plt.legend(['retransmission_a2b','RTT_a2b'])\n",
    "plt.title(\"association between retransmission and RTT (a to b)\")\n",
    "plt.xlabel(\"sample index\")\n",
    "plt.ylabel(\"value\")\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(x_axis,retrans_b2a/retrans_b2a.max(), alpha=0.5)\n",
    "plt.plot(x_axis,rtt_b2a/rtt_b2a.max(), alpha=0.5)\n",
    "plt.legend(['RTT_b2a','retransmission_b2a'])\n",
    "plt.title(\"association between retransmission and RTT (b to a)\")\n",
    "plt.xlabel(\"sample index\")\n",
    "plt.ylabel(\"value\")\n",
    "\n",
    "\n",
    "# variance\n",
    "print(\"variance of retransmission(a to b):\")\n",
    "print(retrans_a2b.var())\n",
    "print(\"variance of retransmission(b to a):\")\n",
    "print(retrans_b2a.var())\n",
    "print(\"variance of RTT(a to b):\")\n",
    "print(rtt_a2b.var())\n",
    "print(\"variance of RTT(b to a):\")\n",
    "print(rtt_b2a.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total traffic volume during TCP connections(in bytes):\n",
      "442593154\n"
     ]
    }
   ],
   "source": [
    "df_ps2 = pd.read_csv(\"./t1_data/PS2.csv\")\n",
    "df_ps2 = df_ps2.sort_values('first')\n",
    "start = df_ps3.loc[:,'first_packet'].tolist()\n",
    "end = df_ps3.loc[:,'last_packet'].tolist()\n",
    "start_list = [float(x) for x in start]\n",
    "end_list = [float(x) for x in end]\n",
    "\n",
    "\n",
    "i = 0\n",
    "total_volume = 0\n",
    "while start_list != []:\n",
    "    start2 = df_ps2.iloc[i,9]\n",
    "    end2 = df_ps2.iloc[i,10]\n",
    "    if start2 >= start_list[0] and end2 <= end_list[0]:\n",
    "        total_volume += df_ps2.iloc[i,7]\n",
    "        i+=1\n",
    "    else:\n",
    "        if end2 >= end_list[0]:\n",
    "            start_list.pop(0)\n",
    "            end_list.pop(0)\n",
    "        elif end2 < end_list[0]:\n",
    "            i+=1\n",
    "    \n",
    "print(\"total traffic volume during TCP connections(in bytes):\")\n",
    "print(total_volume)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4586f53d57779bc929cc5baea2ab63449d60be19617b43dd3ce46f1277d9d25e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
