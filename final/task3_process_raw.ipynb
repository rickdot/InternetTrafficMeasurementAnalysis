{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from pandas.core.frame import DataFrame\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from statsmodels import robust\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_check(file_name):\n",
    "    '''\n",
    "    This function can be used to determine the name of the server.\n",
    "    '''\n",
    "    \n",
    "    server = 'www.superhappy.com'\n",
    "    \n",
    "    if 'nameserver1' in file_name:\n",
    "        server = 'e.ext.nic.fr'\n",
    "    elif 'nameserver2' in file_name:\n",
    "        server = 'f.ext.nic.fr'\n",
    "    elif 'nameserver3' in file_name:\n",
    "        server = 'g.ext.nic.fr'\n",
    "        \n",
    "    elif 'res1' in file_name:\n",
    "        server = 'lej-de.ark.caida.org'\n",
    "    elif 'res2' in file_name:\n",
    "        server = 'per-au.ark.caida.orgf'\n",
    "    elif 'res3' in file_name:\n",
    "        server = 'san-us.ark.caida.org'\n",
    "        \n",
    "    elif 'iperf1' in file_name or 'th1' in file_name:\n",
    "        server = 'ok1.iperf.comnet-student.eu'\n",
    "    elif 'iperf2' in file_name or 'th2' in file_name:\n",
    "        server = 'blr1.iperf.comnet-student.eu'\n",
    "    \n",
    "    return server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing\n",
    "Latency (data sets AS1.x), where x includes: <br>\n",
    "3 name servers with DNS (d1, d2, d3) ,ICMP (n1, n2, n3),  <br>\n",
    "3 research servers (r1, r2, r3) <br>\n",
    "2 iperf servers (i1, i2). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some changes have been made to the original code from assignment1 demo\n",
    "def from_pings(file_name, output):\n",
    "    \n",
    "    # Firstly, read the file\n",
    "    f = open(\"t3_data/\"+file_name,'r')\n",
    "    \n",
    "    # Create some lists to store the desired values\n",
    "    server_list = [] \n",
    "    timestamp_list = [] \n",
    "    typess = []\n",
    "    seqs = []\n",
    "    ttls = []\n",
    "    rtts = []\n",
    "    \n",
    "    # Read through all lines\n",
    "    for line in f:\n",
    "        if '64 bytes from' in line: \n",
    "            time = re.split(' |=',line)[0][1:-1]\n",
    "            seq = re.split(' |=',line)[7]\n",
    "            ttl = re.split(' |=',line)[9]\n",
    "            rtt = re.split(' |=',line)[11]\n",
    "            timestamp_list.append(time)\n",
    "            seqs.append(seq)\n",
    "            ttls.append(ttl)\n",
    "            rtts.append(rtt)\n",
    "            server_list.append(server_check(file_name))\n",
    "            typess.append('ping')\n",
    "        \n",
    "        if 'no answer yet' in line:\n",
    "            time = re.split(' |=',line)[0][1:-1]\n",
    "            seq = re.split(' |=',line)[6]\n",
    "            ttl = float(\"+inf\")\n",
    "            rtt = float(\"+inf\") # Use inf to indicate packet loss \n",
    "            timestamp_list.append(time)\n",
    "            seqs.append(seq)\n",
    "            ttls.append(ttl)\n",
    "            rtts.append(rtt)\n",
    "            server_list.append(server_check(file_name))\n",
    "            typess.append('ping')\n",
    "\n",
    "    # Convert the lists to Dataframe\n",
    "    data = {\"Timestamp\": timestamp_list,\n",
    "            \"Target\": server_list,\n",
    "            \"Type of measurement\": typess,\n",
    "            \"ICMP seq\": seqs,\n",
    "            \"TTLs\": ttls,\n",
    "            \"RTTs (ms)\": rtts}\n",
    "\n",
    "    df = DataFrame(data)\n",
    "    df = df.sort_values(by=[\"Timestamp\"])\n",
    "    \n",
    "    # Write DataFrame to a csv file\n",
    "    df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dig(file_name, output):\n",
    "        \n",
    "    # Firstly, read the file\n",
    "    f = open(\"t3_data/\"+file_name,'r')\n",
    "    \n",
    "    # Create some lists to store the desired values\n",
    "    server_list = [] \n",
    "    timestamp_list = [] \n",
    "    typess = []\n",
    "    query_times = []\n",
    "    \n",
    "    # Read through all lines\n",
    "    for line in f:\n",
    "        if 'Start' in line: \n",
    "            time = re.split(' ',line)[1]\n",
    "            timestamp_list.append(time)\n",
    "        \n",
    "        if 'Query time' in line:\n",
    "            query_time = re.split(' ',line)[3]\n",
    "            query_times.append(query_time)\n",
    "            server_list.append(server_check(file_name))\n",
    "            typess.append('dns')\n",
    "\n",
    "    # Convert the lists to Dataframe\n",
    "    data = {\"Timestamp\": timestamp_list,\n",
    "            \"Target\": server_list,\n",
    "            \"Type of measurement\": typess,\n",
    "            \"Query time (ms)\": query_times}\n",
    "\n",
    "    df = DataFrame(data)\n",
    "    df = df.sort_values(by=[\"Timestamp\"])\n",
    "    \n",
    "    # Write DataFrame to a csv file\n",
    "    df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_curl(file_name, output):\n",
    "            \n",
    "    # Firstly, read the file\n",
    "    f = open(\"t3_data/\"+file_name,'r')\n",
    "    \n",
    "    # Create some lists to store the desired values\n",
    "    server_list = [] \n",
    "    timestamp_list = [] \n",
    "    typess = []\n",
    "    download_speed = []\n",
    "    tcp_time = []\n",
    "    size_download = []\n",
    "    \n",
    "    # Read through all lines\n",
    "    for line in f:\n",
    "        if 'Start' in line: \n",
    "            time = re.split(' ',line)[1]\n",
    "            timestamp_list.append(time)\n",
    "        \n",
    "        else:\n",
    "            tcp = float(re.split(',',line)[1]) - float(re.split(',',line)[0]) # TCP latency got from time_connect minus time_namelookup\n",
    "            speed = re.split(',',line)[4]\n",
    "            size = re.split(',',line)[5]\n",
    "            tcp_time.append(tcp)\n",
    "            size_download.append(size)\n",
    "            download_speed.append(float(speed) * 8)\n",
    "            server_list.append(server_check(file_name))\n",
    "            typess.append('http')\n",
    "\n",
    "    # Convert the lists to Dataframe\n",
    "    data = {\"Timestamp\": timestamp_list,\n",
    "            \"Target\": server_list,\n",
    "            \"Type of measurement\": typess,\n",
    "            \"TCP latency (s)\": tcp_time,\n",
    "            \"Size download (byte)\": size_download,\n",
    "            \"Download speed (bps)\": download_speed}\n",
    "    \n",
    "    df = DataFrame(data)\n",
    "    df = df.sort_values(by=[\"Timestamp\"])\n",
    "    \n",
    "    # Write DataFrame to a csv file\n",
    "    df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"./t3_data/\"):\n",
    "    if file_name.endswith('ping.txt'):  # Find all ‘ping’ files\n",
    "        output = os.path.splitext(file_name)[0] + '.csv'\n",
    "        from_pings(file_name, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"./t3_data/\"):\n",
    "    if file_name.endswith('dig.txt'):  # Find all ‘dig’ files\n",
    "        output = os.path.splitext(file_name)[0] + '.csv'\n",
    "        from_dig(file_name, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(\"./t3_data/\"):\n",
    "    if file_name.endswith('curl.txt'):  # Find all ‘curl’ files\n",
    "        output = os.path.splitext(file_name)[0] + '.csv'\n",
    "        from_curl(file_name, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_onefile(json_file):\n",
    "    with open(\"t3_data/\"+json_file) as json_file:\n",
    "        try:\n",
    "            f = json.load(json_file) # Read the file\n",
    "\n",
    "            # Extract useful data\n",
    "            timestamp = f['start']['timestamp']['timesecs']\n",
    "            server = f['start']['connecting_to']['host']\n",
    "            port = f['start']['connecting_to']['port']\n",
    "            protocol = f['start']['test_start']['protocol']\n",
    "            mode = f['start']['test_start']['reverse']\n",
    "\n",
    "            sent_rate = f['end']['sum_sent']['bits_per_second']\n",
    "            sent_byte = f['end']['sum_sent']['bytes']\n",
    "            retransmission = f['end']['sum_sent']['retransmits']\n",
    "\n",
    "            receive_rate = f['end']['sum_received']['bits_per_second']\n",
    "            receive_byte = f['end']['sum_received']['bytes']\n",
    "\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            pass        # invalid json file, just ignore\n",
    "\n",
    "        except KeyError:            # tried to read non existent value\n",
    "            timestamp = -1\n",
    "            server = str(-1)\n",
    "            port = str(-1)\n",
    "            protocol = str(-1)\n",
    "            mode = str(-1)\n",
    "\n",
    "            sent_rate = str(-1)\n",
    "            sent_byte = str(-1)\n",
    "            retransmission = str(-1)\n",
    "\n",
    "            receive_rate = str(-1)\n",
    "            receive_byte = str(-1)\n",
    "\n",
    "    return [timestamp,server,port,protocol,mode,sent_rate,sent_byte,retransmission,receive_rate,receive_byte]\n",
    "\n",
    "\n",
    "def from_iperf(mode,output):\n",
    "    \n",
    "    # First, create a list of headers and a list of stored data\n",
    "    headers = [\"Timestamp\",\"Server\",\"Port\",\"Type\",\"Mode\",\"Sent bitrate (bps)\",\"Sent bytes\",\"Retransmissions\",\"Receive bitrate (bps)\",\"Receive bytes\"]\n",
    "    all_in = []\n",
    "    \n",
    "    # Because there are many json files, we need to traverse them to extract all the required data\n",
    "    for file_name in os.listdir(\"./t3_data/\"):\n",
    "        if file_name.startswith(mode) and file_name.endswith('.json'): # Find all ‘json’ files\n",
    "            aone = from_onefile(file_name)\n",
    "            all_in.append(aone)\n",
    "    \n",
    "    # From list to dataframe\n",
    "    df = pd.DataFrame(all_in, columns=headers)\n",
    "    df = df.sort_values(by=[\"Timestamp\"])\n",
    "    \n",
    "    # From dataframe to csv\n",
    "    df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_iperf('one','th_one.csv')\n",
    "from_iperf('two','th_two.csv')\n",
    "from_iperf('rone','th_one_r.csv')\n",
    "from_iperf('rtwo','th_two_r.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4586f53d57779bc929cc5baea2ab63449d60be19617b43dd3ce46f1277d9d25e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
